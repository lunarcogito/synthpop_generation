{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install numpy scipy theano-lstm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install git+https://github.com/vishnubob/python-midi@feature/python3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import midi\n",
    "import midi.fileio as midi\n",
    "\n",
    "import theano, theano.tensor as T\n",
    "import numpy as np\n",
    "import theano_lstm\n",
    "\n",
    "import theano, theano.tensor as T\n",
    "import numpy #as np\n",
    "\n",
    "#from data import noteStateSingleToInputForm\n",
    "\n",
    "import os, random\n",
    "#from midi_to_statematrix import *\n",
    "#from data import *\n",
    "import pickle #as cPickle\n",
    "#import cPickle as pickle\n",
    "\n",
    "import signal\n",
    "\n",
    "#from out_to_in_op import OutputFormToInputFormOp\n",
    "\n",
    "import itertools\n",
    "#from midi_to_statematrix import upperBound, lowerBound\n",
    "\n",
    "#import os, random\n",
    "#from midi_to_statematrix import *\n",
    "#from data import *\n",
    "\n",
    "import signal\n",
    "import gzip\n",
    "\n",
    "from theano_lstm import Embedding, LSTM, RNN, StackedCells, Layer, create_optimization_updates, masked_loss, MultiDropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lowerBound = 24\n",
    "upperBound = 102"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def midiToNoteStateMatrix(midifile):\n",
    "\n",
    "    pattern = midi.read_midifile(midifile)\n",
    "\n",
    "    timeleft = [track[0].tick for track in pattern]\n",
    "\n",
    "    posns = [0 for track in pattern]\n",
    "\n",
    "    statematrix = []\n",
    "    span = upperBound-lowerBound\n",
    "    time = 0\n",
    "\n",
    "    state = [[0,0] for x in range(span)]\n",
    "    statematrix.append(state)\n",
    "    while True:\n",
    "        if time % (pattern.resolution / 4) == (pattern.resolution / 8):\n",
    "        #if time % (pattern.resolution / 8) == (pattern.resolution / 8):\n",
    "            # Crossed a note boundary. Create a new state, defaulting to holding notes\n",
    "            oldstate = state\n",
    "            state = [[oldstate[x][0],0] for x in range(span)]\n",
    "            statematrix.append(state)\n",
    "\n",
    "        for i in range(len(timeleft)):\n",
    "            while timeleft[i] == 0:\n",
    "                track = pattern[i]\n",
    "                pos = posns[i]\n",
    "\n",
    "                evt = track[pos]\n",
    "                if isinstance(evt, midi.NoteEvent):\n",
    "                    if (evt.pitch < lowerBound) or (evt.pitch >= upperBound):\n",
    "                        pass\n",
    "                        # print \"Note {} at time {} out of bounds (ignoring)\".format(evt.pitch, time)\n",
    "                    else:\n",
    "                        if isinstance(evt, midi.NoteOffEvent) or evt.velocity == 0:\n",
    "                            state[evt.pitch-lowerBound] = [0, 0]\n",
    "                        else:\n",
    "                            state[evt.pitch-lowerBound] = [1, 1]\n",
    "                elif isinstance(evt, midi.TimeSignatureEvent):\n",
    "                    if evt.numerator not in (2, 4):\n",
    "                        # We don't want to worry about non-4 time signatures. Bail early!\n",
    "                        # print \"Found time signature event {}. Bailing!\".format(evt)\n",
    "                        #return statematrix\n",
    "                        statematrix = statematrix\n",
    "\n",
    "                try:\n",
    "                    timeleft[i] = track[pos + 1].tick\n",
    "                    posns[i] += 1\n",
    "                except IndexError:\n",
    "                    timeleft[i] = None\n",
    "\n",
    "            if timeleft[i] is not None:\n",
    "                timeleft[i] -= 1\n",
    "\n",
    "        if all(t is None for t in timeleft):\n",
    "            break\n",
    "\n",
    "        time += 1\n",
    "\n",
    "    return statematrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def noteStateMatrixToMidi(statematrix, name=\"example\"):\n",
    "    statematrix = numpy.asarray(statematrix)\n",
    "    pattern = midi.Pattern()\n",
    "    track = midi.Track()\n",
    "    pattern.append(track)\n",
    "    \n",
    "    span = upperBound-lowerBound\n",
    "    tickscale = 55\n",
    "    \n",
    "    lastcmdtime = 0\n",
    "    prevstate = [[0,0] for x in range(span)]\n",
    "    for time, state in enumerate(statematrix + [prevstate[:]]):  \n",
    "        offNotes = []\n",
    "        onNotes = []\n",
    "        for i in range(span):\n",
    "            n = state[i]\n",
    "            p = prevstate[i]\n",
    "            if p[0] == 1:\n",
    "                if n[0] == 0:\n",
    "                    offNotes.append(i)\n",
    "                elif n[1] == 1:\n",
    "                    offNotes.append(i)\n",
    "                    onNotes.append(i)\n",
    "            elif n[0] == 1:\n",
    "                onNotes.append(i)\n",
    "        for note in offNotes:\n",
    "            track.append(midi.NoteOffEvent(tick=(time-lastcmdtime)*tickscale, pitch=note+lowerBound))\n",
    "            lastcmdtime = time\n",
    "        for note in onNotes:\n",
    "            track.append(midi.NoteOnEvent(tick=(time-lastcmdtime)*tickscale, velocity=40, pitch=note+lowerBound))\n",
    "            lastcmdtime = time\n",
    "            \n",
    "        prevstate = state\n",
    "    \n",
    "    eot = midi.EndOfTrackEvent(tick=1)\n",
    "    track.append(eot)\n",
    "\n",
    "    midi.write_midifile(\"{}.mid\".format(name), pattern)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OutputFormToInputFormOp(theano.Op):\n",
    "    # Properties attribute\n",
    "    __props__ = ()\n",
    "\n",
    "    def make_node(self, state, time):\n",
    "        state = T.as_tensor_variable(state)\n",
    "        time = T.as_tensor_variable(time)\n",
    "        return theano.Apply(self, [state, time], [T.bmatrix()])\n",
    "    \n",
    "    # Python implementation:\n",
    "    def perform(self, node, inputs_storage, output_storage):\n",
    "        state, time = inputs_storage\n",
    "        output_storage[0][0] = np.array(noteStateSingleToInputForm(state, time), dtype='int8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def startSentinel():\n",
    "    def noteSentinel(note):\n",
    "        position = note\n",
    "        part_position = [position]\n",
    "        \n",
    "        pitchclass = (note + lowerBound) % 12\n",
    "        part_pitchclass = [int(i == pitchclass) for i in range(12)]\n",
    "        \n",
    "        return part_position + part_pitchclass + [0]*66 + [1] \n",
    "    return [noteSentinel(note) for note in range(upperBound-lowerBound)]\n",
    "\n",
    "def getOrDefault(l, i, d):\n",
    "    try:\n",
    "        return l[i]\n",
    "    except IndexError:\n",
    "        return d\n",
    "\n",
    "def buildContext(state):\n",
    "    context = [0]*12\n",
    "    for note, notestate in enumerate(state):\n",
    "        if notestate[0] == 1:\n",
    "            pitchclass = (note + lowerBound) % 12\n",
    "            context[pitchclass] += 1\n",
    "    return context\n",
    "    \n",
    "def buildBeat(time):\n",
    "    return [2*x-1 for x in [time%2, (time//2)%2, (time//4)%2, (time//8)%2]]\n",
    "\n",
    "def noteInputForm(note, state, context, beat):\n",
    "    position = note\n",
    "    part_position = [position]\n",
    "\n",
    "    pitchclass = (note + lowerBound) % 12\n",
    "    part_pitchclass = [int(i == pitchclass) for i in range(12)]\n",
    "    # Concatenate the note states for the previous vicinity\n",
    "    part_prev_vicinity = list(itertools.chain.from_iterable((getOrDefault(state, note+i, [0,0]) for i in range(-12, 13))))\n",
    "\n",
    "    part_context = context[pitchclass:] + context[:pitchclass]\n",
    "\n",
    "    return part_position + part_pitchclass + part_prev_vicinity + part_context + beat + [0]\n",
    "\n",
    "def noteStateSingleToInputForm(state,time):\n",
    "    beat = buildBeat(time)\n",
    "    context = buildContext(state)\n",
    "    return [noteInputForm(note, state, context, beat) for note in range(len(state))]\n",
    "\n",
    "def noteStateMatrixToInputForm(statematrix):\n",
    "    # NOTE: May have to transpose this or transform it in some way to make Theano like it\n",
    "    #[startSentinel()] + \n",
    "    inputform = [ noteStateSingleToInputForm(state,time) for time,state in enumerate(statematrix) ]\n",
    "    return inputform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def has_hidden(layer):\n",
    "    \"\"\"\n",
    "    Whether a layer has a trainable\n",
    "    initial hidden state.\n",
    "    \"\"\"\n",
    "    return hasattr(layer, 'initial_hidden_state')\n",
    "\n",
    "def matrixify(vector, n):\n",
    "    # Cast n to int32 if necessary to prevent error on 32 bit systems\n",
    "    return T.repeat(T.shape_padleft(vector),\n",
    "                    n if (theano.configdefaults.local_bitwidth() == 64) else T.cast(n,'int32'),\n",
    "                    axis=0)\n",
    "\n",
    "def initial_state(layer, dimensions = None):\n",
    "    \"\"\"\n",
    "    Initalizes the recurrence relation with an initial hidden state\n",
    "    if needed, else replaces with a \"None\" to tell Theano that\n",
    "    the network **will** return something, but it does not need\n",
    "    to send it to the next step of the recurrence\n",
    "    \"\"\"\n",
    "    if dimensions is None:\n",
    "        return layer.initial_hidden_state if has_hidden(layer) else None\n",
    "    else:\n",
    "        return matrixify(layer.initial_hidden_state, dimensions) if has_hidden(layer) else None\n",
    "\n",
    "def initial_state_with_taps(layer, dimensions = None):\n",
    "    \"\"\"Optionally wrap tensor variable into a dict with taps=[-1]\"\"\"\n",
    "    state = initial_state(layer, dimensions)\n",
    "    if state is not None:\n",
    "        return dict(initial=state, taps=[-1])\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "class PassthroughLayer(Layer):\n",
    "    \"\"\"\n",
    "    Empty \"layer\" used to get the final output of the LSTM\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.is_recursive = False\n",
    "    \n",
    "    def create_variables(self):\n",
    "        pass\n",
    "    \n",
    "    def activate(self, x):\n",
    "        return x\n",
    "    \n",
    "    @property\n",
    "    def params(self):\n",
    "        return []\n",
    "    \n",
    "    @params.setter\n",
    "    def params(self, param_list):\n",
    "        pass\n",
    "\n",
    "        \n",
    "def get_last_layer(result):\n",
    "    if isinstance(result, list):\n",
    "        return result[-1]\n",
    "    else:\n",
    "        return result\n",
    "\n",
    "def ensure_list(result):\n",
    "    if isinstance(result, list):\n",
    "        return result\n",
    "    else:\n",
    "        return [result]\n",
    "    \n",
    "\n",
    "class Model(object):\n",
    "    \n",
    "    def __init__(self, t_layer_sizes, p_layer_sizes, dropout=0):\n",
    "        \n",
    "        self.t_layer_sizes = t_layer_sizes\n",
    "        self.p_layer_sizes = p_layer_sizes\n",
    "\n",
    "        # From our architecture definition, size of the notewise input\n",
    "        self.t_input_size = 80\n",
    "        \n",
    "        # time network maps from notewise input size to various hidden sizes\n",
    "        self.time_model = StackedCells( self.t_input_size, celltype=LSTM, layers = t_layer_sizes)\n",
    "        self.time_model.layers.append(PassthroughLayer())\n",
    "        \n",
    "        # pitch network takes last layer of time model and state of last note, moving upward\n",
    "        # and eventually ends with a two-element sigmoid layer\n",
    "        p_input_size = t_layer_sizes[-1] + 2\n",
    "        self.pitch_model = StackedCells( p_input_size, celltype=LSTM, layers = p_layer_sizes)\n",
    "        self.pitch_model.layers.append(Layer(p_layer_sizes[-1], 2, activation = T.nnet.sigmoid))\n",
    "        \n",
    "        self.dropout = dropout\n",
    "\n",
    "        self.conservativity = T.fscalar()\n",
    "        self.srng = T.shared_randomstreams.RandomStreams(np.random.randint(0, 1024))\n",
    "\n",
    "        self.setup_train()\n",
    "        self.setup_predict()\n",
    "        self.setup_slow_walk()\n",
    "\n",
    "    @property\n",
    "    def params(self):\n",
    "        return self.time_model.params + self.pitch_model.params\n",
    "    \n",
    "    @params.setter\n",
    "    def params(self, param_list):\n",
    "        ntimeparams = len(self.time_model.params)\n",
    "        self.time_model.params = param_list[:ntimeparams]\n",
    "        self.pitch_model.params = param_list[ntimeparams:]\n",
    "\n",
    "    @property\n",
    "    def learned_config(self):\n",
    "        return [self.time_model.params, self.pitch_model.params, [l.initial_hidden_state for mod in (self.time_model, self.pitch_model) for l in mod.layers if has_hidden(l)]]\n",
    "\n",
    "    @learned_config.setter\n",
    "    def learned_config(self, learned_list):\n",
    "        self.time_model.params = learned_list[0]\n",
    "        self.pitch_model.params = learned_list[1]\n",
    "        for l, val in zip((l for mod in (self.time_model, self.pitch_model) for l in mod.layers if has_hidden(l)), learned_list[2]):\n",
    "            l.initial_hidden_state.set_value(val.get_value())\n",
    "    \n",
    "    def setup_train(self):\n",
    "\n",
    "        # dimensions: (batch, time, notes, input_data) with input_data as in architecture\n",
    "        self.input_mat = T.btensor4()\n",
    "        # dimensions: (batch, time, notes, onOrArtic) with 0:on, 1:artic\n",
    "        self.output_mat = T.btensor4()\n",
    "        \n",
    "        self.epsilon = np.spacing(np.float32(1.0))\n",
    "\n",
    "        def step_time(in_data, *other):\n",
    "            other = list(other)\n",
    "            split = -len(self.t_layer_sizes) if self.dropout else len(other)\n",
    "            hiddens = other[:split]\n",
    "            masks = [None] + other[split:] if self.dropout else []\n",
    "            new_states = self.time_model.forward(in_data, prev_hiddens=hiddens, dropout=masks)\n",
    "            return new_states\n",
    "        \n",
    "        def step_note(in_data, *other):\n",
    "            other = list(other)\n",
    "            split = -len(self.p_layer_sizes) if self.dropout else len(other)\n",
    "            hiddens = other[:split]\n",
    "            masks = [None] + other[split:] if self.dropout else []\n",
    "            new_states = self.pitch_model.forward(in_data, prev_hiddens=hiddens, dropout=masks)\n",
    "            return new_states\n",
    "        \n",
    "        # We generate an output for each input, so it doesn't make sense to use the last output as an input.\n",
    "        # Note that we assume the sentinel start value is already present\n",
    "        # TEMP CHANGE: NO SENTINEL\n",
    "        input_slice = self.input_mat[:,0:-1]\n",
    "        n_batch, n_time, n_note, n_ipn = input_slice.shape\n",
    "        \n",
    "        # time_inputs is a matrix (time, batch/note, input_per_note)\n",
    "        time_inputs = input_slice.transpose((1,0,2,3)).reshape((n_time,n_batch*n_note,n_ipn))\n",
    "        num_time_parallel = time_inputs.shape[1]\n",
    "        \n",
    "        # apply dropout\n",
    "        if self.dropout > 0:\n",
    "            time_masks = theano_lstm.MultiDropout( [(num_time_parallel, shape) for shape in self.t_layer_sizes], self.dropout)\n",
    "        else:\n",
    "            time_masks = []\n",
    "\n",
    "        time_outputs_info = [initial_state_with_taps(layer, num_time_parallel) for layer in self.time_model.layers]\n",
    "        time_result, _ = theano.scan(fn=step_time, sequences=[time_inputs], non_sequences=time_masks, outputs_info=time_outputs_info)\n",
    "        \n",
    "        self.time_thoughts = time_result\n",
    "        \n",
    "        # Now time_result is a list of matrix [layer](time, batch/note, hidden_states) for each layer but we only care about \n",
    "        # the hidden state of the last layer.\n",
    "        # Transpose to be (note, batch/time, hidden_states)\n",
    "        last_layer = get_last_layer(time_result)\n",
    "        n_hidden = last_layer.shape[2]\n",
    "        time_final = get_last_layer(time_result).reshape((n_time,n_batch,n_note,n_hidden)).transpose((2,1,0,3)).reshape((n_note,n_batch*n_time,n_hidden))\n",
    "        \n",
    "        # note_choices_inputs represents the last chosen note. Starts with [0,0], doesn't include last note.\n",
    "        # In (note, batch/time, 2) format\n",
    "        # Shape of start is thus (1, N, 2), concatenated with all but last element of output_mat transformed to (x, N, 2)\n",
    "        start_note_values = T.alloc(np.array(0,dtype=np.int8), 1, time_final.shape[1], 2 )\n",
    "        correct_choices = self.output_mat[:,1:,0:-1,:].transpose((2,0,1,3)).reshape((n_note-1,n_batch*n_time,2))\n",
    "        note_choices_inputs = T.concatenate([start_note_values, correct_choices], axis=0)\n",
    "        \n",
    "        # Together, this and the output from the last LSTM goes to the new LSTM, but rotated, so that the batches in\n",
    "        # one direction are the steps in the other, and vice versa.\n",
    "        note_inputs = T.concatenate( [time_final, note_choices_inputs], axis=2 )\n",
    "        num_timebatch = note_inputs.shape[1]\n",
    "        \n",
    "        # apply dropout\n",
    "        if self.dropout > 0:\n",
    "            pitch_masks = theano_lstm.MultiDropout( [(num_timebatch, shape) for shape in self.p_layer_sizes], self.dropout)\n",
    "        else:\n",
    "            pitch_masks = []\n",
    "\n",
    "        note_outputs_info = [initial_state_with_taps(layer, num_timebatch) for layer in self.pitch_model.layers]\n",
    "        note_result, _ = theano.scan(fn=step_note, sequences=[note_inputs], non_sequences=pitch_masks, outputs_info=note_outputs_info)\n",
    "        \n",
    "        self.note_thoughts = note_result\n",
    "        \n",
    "        # Now note_result is a list of matrix [layer](note, batch/time, onOrArticProb) for each layer but we only care about \n",
    "        # the hidden state of the last layer.\n",
    "        # Transpose to be (batch, time, note, onOrArticProb)\n",
    "        note_final = get_last_layer(note_result).reshape((n_note,n_batch,n_time,2)).transpose(1,2,0,3)\n",
    "        \n",
    "        # The cost of the entire procedure is the negative log likelihood of the events all happening.\n",
    "        # For the purposes of training, if the ouputted probability is P, then the likelihood of seeing a 1 is P, and\n",
    "        # the likelihood of seeing 0 is (1-P). So the likelihood is (1-P)(1-x) + Px = 2Px - P - x + 1\n",
    "        # Since they are all binary decisions, and are all probabilities given all previous decisions, we can just\n",
    "        # multiply the likelihoods, or, since we are logging them, add the logs.\n",
    "        \n",
    "        # Note that we mask out the articulations for those notes that aren't played, because it doesn't matter\n",
    "        # whether or not those are articulated.\n",
    "        # The padright is there because self.output_mat[:,:,:,0] -> 3D matrix with (b,x,y), but we need 3d tensor with \n",
    "        # (b,x,y,1) instead\n",
    "        active_notes = T.shape_padright(self.output_mat[:,1:,:,0])\n",
    "        mask = T.concatenate([T.ones_like(active_notes),active_notes], axis=3)\n",
    "        \n",
    "        loglikelihoods = mask * T.log( 2*note_final*self.output_mat[:,1:] - note_final - self.output_mat[:,1:] + 1 + self.epsilon )\n",
    "        self.cost = T.neg(T.sum(loglikelihoods))\n",
    "        \n",
    "        updates, _, _, _, _ = create_optimization_updates(self.cost, self.params, method=\"adadelta\")\n",
    "        self.update_fun = theano.function(\n",
    "            inputs=[self.input_mat, self.output_mat],\n",
    "            outputs=self.cost,\n",
    "            updates=updates,\n",
    "            allow_input_downcast=True)\n",
    "\n",
    "        self.update_thought_fun = theano.function(\n",
    "            inputs=[self.input_mat, self.output_mat],\n",
    "            outputs= ensure_list(self.time_thoughts) + ensure_list(self.note_thoughts) + [self.cost],\n",
    "            allow_input_downcast=True)\n",
    "    \n",
    "    def _predict_step_note(self, in_data_from_time, *states):\n",
    "        # States is [ *hiddens, last_note_choice ]\n",
    "        hiddens = list(states[:-1])\n",
    "        in_data_from_prev = states[-1]\n",
    "        in_data = T.concatenate([in_data_from_time, in_data_from_prev])\n",
    "\n",
    "        # correct for dropout\n",
    "        if self.dropout > 0:\n",
    "            masks = [1 - self.dropout for layer in self.pitch_model.layers]\n",
    "            masks[0] = None\n",
    "        else:\n",
    "            masks = []\n",
    "\n",
    "        new_states = self.pitch_model.forward(in_data, prev_hiddens=hiddens, dropout=masks)\n",
    "        \n",
    "        # Now new_states is a per-layer set of activations.\n",
    "        probabilities = get_last_layer(new_states)\n",
    "        \n",
    "        # Thus, probabilities is a vector of two probabilities, P(play), and P(artic | play)\n",
    "        \n",
    "        shouldPlay = self.srng.uniform() < (probabilities[0] ** self.conservativity)\n",
    "        shouldArtic = shouldPlay * (self.srng.uniform() < probabilities[1])\n",
    "        \n",
    "        chosen = T.cast(T.stack(shouldPlay, shouldArtic), \"int8\")\n",
    "        \n",
    "        return ensure_list(new_states) + [chosen]\n",
    "\n",
    "    def setup_predict(self):\n",
    "        # In prediction mode, note steps are contained in the time steps. So the passing gets a little bit hairy.\n",
    "\n",
    "        self.predict_seed = T.bmatrix()\n",
    "        self.steps_to_simulate = T.iscalar()\n",
    "\n",
    "        def step_time(*states):\n",
    "            # States is [ *hiddens, prev_result, time]\n",
    "            hiddens = list(states[:-2])\n",
    "            in_data = states[-2]\n",
    "            time = states[-1]\n",
    "\n",
    "            # correct for dropout\n",
    "            if self.dropout > 0:\n",
    "                masks = [1 - self.dropout for layer in self.time_model.layers]\n",
    "                masks[0] = None\n",
    "            else:\n",
    "                masks = []\n",
    "\n",
    "            new_states = self.time_model.forward(in_data, prev_hiddens=hiddens, dropout=masks)\n",
    "            \n",
    "            # Now new_states is a list of matrix [layer](notes, hidden_states) for each layer\n",
    "            time_final = get_last_layer(new_states)\n",
    "            \n",
    "            start_note_values = theano.tensor.alloc(np.array(0,dtype=np.int8), 2)\n",
    "            \n",
    "            # This gets a little bit complicated. In the training case, we can pass in a combination of the\n",
    "            # time net's activations with the known choices. But in the prediction case, those choices don't\n",
    "            # exist yet. So instead of iterating over the combination, we iterate over only the activations,\n",
    "            # and then combine in the previous outputs in the step. And then since we are passing outputs to\n",
    "            # previous inputs, we need an additional outputs_info for the initial \"previous\" output of zero.\n",
    "            note_outputs_info = ([ initial_state_with_taps(layer) for layer in self.pitch_model.layers ] +\n",
    "                                 [ dict(initial=start_note_values, taps=[-1]) ])\n",
    "            \n",
    "            notes_result, updates = theano.scan(fn=self._predict_step_note, sequences=[time_final], outputs_info=note_outputs_info)\n",
    "            \n",
    "            # Now notes_result is a list of matrix [layer/output](notes, onOrArtic)\n",
    "            output = get_last_layer(notes_result)\n",
    "            \n",
    "            next_input = OutputFormToInputFormOp()(output, time + 1) # TODO: Fix time\n",
    "            #next_input = T.cast(T.alloc(0, 3, 4),'int64')\n",
    "            \n",
    "            return (ensure_list(new_states) + [ next_input, time + 1, output ]), updates\n",
    "        \n",
    "        # start_sentinel = startSentinel()\n",
    "        num_notes = self.predict_seed.shape[0]\n",
    "        \n",
    "        time_outputs_info = ([ initial_state_with_taps(layer, num_notes) for layer in self.time_model.layers ] +\n",
    "                             [ dict(initial=self.predict_seed, taps=[-1]),\n",
    "                               dict(initial=0, taps=[-1]),\n",
    "                               None ])\n",
    "            \n",
    "        time_result, updates = theano.scan( fn=step_time, \n",
    "                                            outputs_info=time_outputs_info, \n",
    "                                            n_steps=self.steps_to_simulate )\n",
    "        \n",
    "        self.predict_thoughts = time_result\n",
    "        \n",
    "        self.predicted_output = time_result[-1]\n",
    "        \n",
    "        self.predict_fun = theano.function(\n",
    "            inputs=[self.steps_to_simulate, self.conservativity, self.predict_seed],\n",
    "            outputs=self.predicted_output,\n",
    "            updates=updates,\n",
    "            allow_input_downcast=True)\n",
    "\n",
    "        self.predict_thought_fun = theano.function(\n",
    "            inputs=[self.steps_to_simulate, self.conservativity, self.predict_seed],\n",
    "            outputs=ensure_list(self.predict_thoughts),\n",
    "            updates=updates,\n",
    "            allow_input_downcast=True)\n",
    "\n",
    "    def setup_slow_walk(self):\n",
    "\n",
    "        self.walk_input = theano.shared(np.ones((2,2), dtype='int8'))\n",
    "        self.walk_time = theano.shared(np.array(0, dtype='int64'))\n",
    "        self.walk_hiddens = [theano.shared(np.ones((2,2), dtype=theano.config.floatX)) for layer in self.time_model.layers if has_hidden(layer)]\n",
    "        \n",
    "        # correct for dropout\n",
    "        if self.dropout > 0:\n",
    "            masks = [1 - self.dropout for layer in self.time_model.layers]\n",
    "            masks[0] = None\n",
    "        else:\n",
    "            masks = []\n",
    "\n",
    "        new_states = self.time_model.forward(self.walk_input, prev_hiddens=self.walk_hiddens, dropout=masks)\n",
    "\n",
    "        # Now new_states is a list of matrix [layer](notes, hidden_states) for each layer\n",
    "        time_final = get_last_layer(new_states)\n",
    "        \n",
    "        start_note_values = theano.tensor.alloc(np.array(0,dtype=np.int8), 2)\n",
    "        note_outputs_info = ([ initial_state_with_taps(layer) for layer in self.pitch_model.layers ] +\n",
    "                             [ dict(initial=start_note_values, taps=[-1]) ])\n",
    "        \n",
    "        notes_result, updates = theano.scan(fn=self._predict_step_note, sequences=[time_final], outputs_info=note_outputs_info)\n",
    "        \n",
    "        # Now notes_result is a list of matrix [layer/output](notes, onOrArtic)\n",
    "        output = get_last_layer(notes_result)\n",
    "        \n",
    "        next_input = OutputFormToInputFormOp()(output, self.walk_time + 1) # TODO: Fix time\n",
    "        #next_input = T.cast(T.alloc(0, 3, 4),'int64')\n",
    "\n",
    "        slow_walk_results = (new_states[:-1] + notes_result[:-1] + [ next_input, output ])\n",
    "\n",
    "        updates.update({\n",
    "                self.walk_time: self.walk_time+1,\n",
    "                self.walk_input: next_input\n",
    "            })\n",
    "\n",
    "        updates.update({hidden:newstate for hidden, newstate, layer in zip(self.walk_hiddens, new_states, self.time_model.layers) if has_hidden(layer)})\n",
    "\n",
    "        self.slow_walk_fun = theano.function(\n",
    "            inputs=[self.conservativity],\n",
    "            outputs=slow_walk_results,\n",
    "            updates=updates,\n",
    "            allow_input_downcast=True)\n",
    "\n",
    "    def start_slow_walk(self, seed):\n",
    "        seed = np.array(seed)\n",
    "        num_notes = seed.shape[0]\n",
    "\n",
    "        self.walk_time.set_value(0)\n",
    "        self.walk_input.set_value(seed)\n",
    "        for layer, hidden in zip((l for l in self.time_model.layers if has_hidden(l)),self.walk_hiddens):\n",
    "            hidden.set_value(np.repeat(np.reshape(layer.initial_hidden_state.get_value(), (1,-1)), num_notes, axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_width = 2 # number of sequences in a batch\n",
    "batch_len = 16*8 # length of each sequence\n",
    "division_len = 16 # interval between possible start locations\n",
    "\n",
    "def loadPieces(dirpath):\n",
    "\n",
    "    pieces = {}\n",
    "\n",
    "    for fname in os.listdir(dirpath):\n",
    "        if fname[-4:] not in ('.mid','.MID'):\n",
    "            continue\n",
    "\n",
    "        name = fname[:-4]\n",
    "\n",
    "        outMatrix = midiToNoteStateMatrix(os.path.join(dirpath, fname))\n",
    "        if len(outMatrix) < batch_len:\n",
    "            continue\n",
    "\n",
    "        pieces[name] = outMatrix\n",
    "        print(\"Loaded {}\".format(name))\n",
    "\n",
    "    return pieces\n",
    "\n",
    "def getPieceSegment(pieces):\n",
    "    piece_output = random.choice(list(pieces.values()))\n",
    "    start = random.randrange(0,len(piece_output)-batch_len,division_len)\n",
    "    # print \"Range is {} {} {} -> {}\".format(0,len(piece_output)-batch_len,division_len, start)\n",
    "\n",
    "    seg_out = piece_output[start:start+batch_len]\n",
    "    seg_in = noteStateMatrixToInputForm(seg_out)\n",
    "\n",
    "    return seg_in, seg_out\n",
    "\n",
    "def getPieceBatch(pieces):\n",
    "    i,o = zip(*[getPieceSegment(pieces) for _ in range(batch_width)])\n",
    "    return numpy.array(i), numpy.array(o)\n",
    "\n",
    "def trainPiece(model,pieces,epochs,start=0):\n",
    "    stopflag = [False]\n",
    "    def signal_handler(signame, sf):\n",
    "        stopflag[0] = True\n",
    "    old_handler = signal.signal(signal.SIGINT, signal_handler)\n",
    "    for i in range(start,start+epochs):\n",
    "        if stopflag[0]:\n",
    "            break\n",
    "        error = model.update_fun(*getPieceBatch(pieces))\n",
    "        if i % 100 == 0:\n",
    "            print(\"epoch {}, error={}\".format(i,error))\n",
    "        if i % 500 == 0 or (i % 100 == 0 and i < 1000):\n",
    "            xIpt, xOpt = map(numpy.array, getPieceSegment(pieces))\n",
    "            noteStateMatrixToMidi(numpy.concatenate((numpy.expand_dims(xOpt[0], 0), \n",
    "                                                     model.predict_fun(batch_len, 1, xIpt[0])), axis=0),\n",
    "                                  'output_pop_1/sample{}'.format(i))\n",
    "            pickle.dump(model.learned_config,open('output_pop_1/params{}.p'.format(i), 'wb'))\n",
    "    signal.signal(signal.SIGINT, old_handler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pcs = loadPieces('/Users/tzobnina/Synth pop MIDI')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_adaptive(m,pcs,times,keep_thoughts=False,name=\"final\"):\n",
    "    xIpt, xOpt = map(lambda x: numpy.array(x, dtype='int8'), getPieceSegment(pcs))\n",
    "    all_outputs = [xOpt[0]]\n",
    "    if keep_thoughts:\n",
    "        all_thoughts = []\n",
    "    m.start_slow_walk(xIpt[0])\n",
    "    cons = 1\n",
    "    for time in range(batch_len*times):\n",
    "        resdata = m.slow_walk_fun( cons )\n",
    "        nnotes = numpy.sum(resdata[-1][:,0])\n",
    "        if nnotes < 2:\n",
    "            if cons > 1:\n",
    "                cons = 1\n",
    "            cons -= 0.02\n",
    "        else:\n",
    "            cons += (1 - cons)*0.3\n",
    "        all_outputs.append(resdata[-1])\n",
    "        if keep_thoughts:\n",
    "            all_thoughts.append(resdata)\n",
    "    noteStateMatrixToMidi(numpy.array(all_outputs),'output_pop/'+name)\n",
    "    if keep_thoughts:\n",
    "        pickle.dump(all_thoughts, open('output_pop/'+name+'.p','wb'))\n",
    "\n",
    "def fetch_train_thoughts(m,pcs,batches,name=\"trainthoughts\"):\n",
    "    all_thoughts = []\n",
    "    for i in range(batches):\n",
    "        ipt, opt = getPieceBatch(pcs)\n",
    "        thoughts = m.update_thought_fun(ipt,opt)\n",
    "        all_thoughts.append((ipt,opt,thoughts))\n",
    "    pickle.dump(all_thoughts, open('output_pop/'+name+'.p','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "\n",
    "    #pcs = loadPieces('/Users/tzobnina/Synth pop MIDI')\n",
    "    m = Model([300,300],[100,50], dropout=0.5)\n",
    "    trainPiece(m, pcs, 300)\n",
    "    pickle.dump(m.learned_config, open( \"output_pop/final_learned_config.p\", \"wb\" ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_adaptive(m,pcs,10,name=\"composition_pop\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
